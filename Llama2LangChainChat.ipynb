{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1xp5hypAX7DCxJKRc_gaubdOeNqqdsnFx",
      "authorship_tag": "ABX9TyNiDu4cTrhaJd3ZDnsFqwwU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0dbb424bb1864edeaaffd9ca1de4fef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_543721e615274f92a56e9ecfd9094b9c",
              "IPY_MODEL_621503bd0c5f4449865415084cade2a8",
              "IPY_MODEL_f76696744fe24c88bcc544d226ac6dcb"
            ],
            "layout": "IPY_MODEL_2bf0207dccf34dffae82417d10c8267a"
          }
        },
        "543721e615274f92a56e9ecfd9094b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_146f2706a6174d54921d56a13c354d98",
            "placeholder": "​",
            "style": "IPY_MODEL_8138f31ca0c24087b4f6b8438b0eee2a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "621503bd0c5f4449865415084cade2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_984bf13b73024a5b9d1eaf3266dee222",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bcba0cb954d4cdb95e4d0ba83927549",
            "value": 2
          }
        },
        "f76696744fe24c88bcc544d226ac6dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3abc04e1c2144ddaa2524630149e559",
            "placeholder": "​",
            "style": "IPY_MODEL_79f2dddf81f14f2b8f228b154acf1248",
            "value": " 2/2 [01:04&lt;00:00, 29.46s/it]"
          }
        },
        "2bf0207dccf34dffae82417d10c8267a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "146f2706a6174d54921d56a13c354d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8138f31ca0c24087b4f6b8438b0eee2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "984bf13b73024a5b9d1eaf3266dee222": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bcba0cb954d4cdb95e4d0ba83927549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3abc04e1c2144ddaa2524630149e559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79f2dddf81f14f2b8f228b154acf1248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaydip1989/LlamaChat/blob/main/Llama2LangChainChat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4mORol111lq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a83f05d-60cf-4f3f-dcf7-20451bee9db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Llama2LangChainPDFChat\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/Llama2LangChainPDFChat'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "LRoOITK62DmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "484cfbd5-cf9c-4fd4-a8a0-cbdb75df2efe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Llama2LangChainPDFChat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain transformers accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "TtfEym2Qq5Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "F_lEIbhUq5AM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a22f56-bd8c-4e59-ad90-42f1c752246b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct 15 07:58:07 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain, SequentialChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "from transformers import AutoModel\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import json, textwrap"
      ],
      "metadata": {
        "id": "Scx9d-t7q48w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('NousResearch/Llama-2-7b-chat-hf')"
      ],
      "metadata": {
        "id": "pv9h32moq45H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c2a642d-fdff-4143-caf9-82b3454ff76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"NousResearch/Llama-2-7b-chat-hf\",\n",
        "    device_map = \"auto\",\n",
        "    torch_dtype = torch.float16,\n",
        "    load_in_4bit = True,\n",
        "    bnb_4bit_quant_type = \"nf4\",\n",
        "    bnb_4bit_compute_dtype = torch.float16\n",
        ")"
      ],
      "metadata": {
        "id": "ESPpQ5btq41W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "0dbb424bb1864edeaaffd9ca1de4fef2",
            "543721e615274f92a56e9ecfd9094b9c",
            "621503bd0c5f4449865415084cade2a8",
            "f76696744fe24c88bcc544d226ac6dcb",
            "2bf0207dccf34dffae82417d10c8267a",
            "146f2706a6174d54921d56a13c354d98",
            "8138f31ca0c24087b4f6b8438b0eee2a",
            "984bf13b73024a5b9d1eaf3266dee222",
            "4bcba0cb954d4cdb95e4d0ba83927549",
            "e3abc04e1c2144ddaa2524630149e559",
            "79f2dddf81f14f2b8f228b154acf1248"
          ]
        },
        "outputId": "6b24b226-df2e-4887-9ea9-28d6b3e39684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dbb424bb1864edeaaffd9ca1de4fef2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    torch_dtype = torch.float16,\n",
        "    device_map = \"auto\",\n",
        "    max_new_tokens = 512,\n",
        "    do_sample = True,\n",
        "    top_k = 30,\n",
        "    num_return_sequences = 1,\n",
        "    eos_token_id = tokenizer.eos_token_id\n",
        ")"
      ],
      "metadata": {
        "id": "2mLU_t_Fq4yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.llama.tokenization_llama_fast import DEFAULT_SYSTEM_PROMPT\n",
        "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
        "B_SYS, E_SYS = \"<>\\n\", \"\\n<>\\n\\n\"\n",
        "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
        "You are an advanced Life guru and mental health expert that excels at giving advice.\n",
        "Always be as helpful as possible, while being safe.Your answers should not include any harmful, unethical,racist,\n",
        "sexist, toxic, dangerous or illegal content.Also make sure that the responses are socially unbiased and positive\n",
        "in nature.\n",
        "If a question does not make any sense or is not factually coherent, explain why instead of giving incorrect or garbage answers.\n",
        "If you don't know the answer to a question, please don't share false information.Just say you don't know and you are\n",
        "sorry!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pumftM4aq4uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT, citation=None):\n",
        "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
        "    prompt_template = B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
        "\n",
        "    if citation:\n",
        "        prompt_template = f\"\\n\\n Citation: {citation}\" # Insert citation here\n",
        "    return prompt_template\n",
        "\n",
        "def cut_off_text(text, prompt):\n",
        "    cutoff_phrase = prompt\n",
        "    index = text.find(cutoff_phrase)\n",
        "    if index != -1:\n",
        "        return text[:index]\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "def remove_substring(string, substring):\n",
        "    return string.replace(substring, \"\")\n",
        "\n",
        "def generate(text, citation=None):\n",
        "    prompt = get_prompt(text, citation = citation)\n",
        "    inputs = tokenizer(prompt, return_tensors = \"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs,\n",
        "                                 max_length = 512,\n",
        "                                 eos_token_id = tokenizer.eos_token_id,\n",
        "                                 pad_token_id = tokenizer.eos_token_id\n",
        "                                 )\n",
        "        final_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "        final_outputs = cut_off_text(final_outputs, '')\n",
        "        final_outputs = remove_substring(final_outputs, prompt)\n",
        "    return final_outputs\n",
        "\n",
        "def parse_text(text):\n",
        "    wrapped_text = textwrap.fill(text, width=100)\n",
        "    print(wrapped_text + '\\n\\n')"
      ],
      "metadata": {
        "id": "K3K-9tkQq4r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(\n",
        "    pipeline = pipe,\n",
        "    model_kwargs = {'temperature':0.7,'max_length':256, 'top_k':50}\n",
        ")"
      ],
      "metadata": {
        "id": "Rwi71C22Mwz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are an advanced Life guru and mental health expert that excels at giving advice. \"\n",
        "instruction = \"Convert the following input text from a stupid human to a well-reasoned and step-by-step \\\n",
        "throughout adice:\\n\\n {text}\"\n",
        "template = get_prompt(instruction, system_prompt)\n",
        "print(template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66F6YDc1Mwwm",
        "outputId": "29af65cd-16d8-484a-d98d-68c305e250b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INST]<>\n",
            "You are an advanced Life guru and mental health expert that excels at giving advice. \n",
            "<>\n",
            "\n",
            "Convert the following input text from a stupid human to a well-reasoned and step-by-step throughout adice:\n",
            "\n",
            " {text}[/INST]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(template = template, input_variables = ['text'])\n",
        "llm_chain = LLMChain(prompt = prompt, llm = llm, verbose = False)"
      ],
      "metadata": {
        "id": "73qq9OmSMwtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"How to distract my mind from negative thoughts? Please don't tell me to meditate.\""
      ],
      "metadata": {
        "id": "R-1EoagGMwpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm_chain.run(text)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHbwHSo2Mwlq",
        "outputId": "94565428-e5f9-4ab4-ebe4-f25e28444ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Ah, I see. *chuckles* Meditation is overrated, I agree. *winks* But, my dear, let me tell you a secret: there are way more effective ways to distract your mind from negative thoughts than just meditating. *nods* Here's what you can try:\n",
            "\n",
            "1. Practice Gratitude: Write down three things you're grateful for each day before you go to bed. It could be something as simple as a good cup of coffee, a beautiful sunset, or a kind word from a friend. Focusing on the good things in life can help shift your perspective and distract you from negative thoughts.\n",
            "2. Engage in a Creative Activity: Sometimes, creating something can be a great way to distract your mind from negative thoughts. Whether it's painting, drawing, writing, or playing music, engage in a creative activity that brings you joy and helps take your mind off of negative thoughts.\n",
            "3. Get Moving: Exercise releases endorphins, which are chemicals in your brain that act as natural painkillers and mood elevators. So, go for a walk, do some yoga, or hit the gym. Not only will you feel better physically, but you'll also mentally.\n",
            "4. Help Others: Helping others can actually help distract your mind from negative thoughts. Volunteer at a local soup kitchen, mentor a student, or simply do a favor for a friend or family member. Giving back to your community can help shift your focus away from negative thoughts.\n",
            "5. Listen to Music: Listening to music can be a great way to distract your mind from negative thoughts. Create a playlist of your favorite songs or try listening to calming music like classical or nature sounds. Research has shown that listening to music can actually reduce symptoms of anxiety and depression.\n",
            "6. Practice Mindfulness: Yes, I know what you're thinking: \"But isn't mindfulness just meditation?\" Not exactly! Mindfulness is the practice of being present in the moment, without judgment. You can practice mindfulness by paying attention to your breath, your body, or your surroundings. It can help distract your mind from negative thoughts and bring you back to the present moment.\n",
            "7. Take a Break: Sometimes, the best way to dist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"How to keep myself rejoiced in between failures?\"\n",
        "response = llm_chain.run(text)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4kFrL9GMwiB",
        "outputId": "bec4da94-2af0-441d-b507-3bec7f23b0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Ah, I see. *adjusts glasses* Well, my dear, it's quite simple, really. The key to rejoicing between failures is all about perspective and mindset. *nods* Here's a step-by-step guide to help you cultivate a joyful attitude, even when things aren't going your way:\n",
            "\n",
            "Step 1: Practice Gratitude\n",
            "The first and foremost thing to do is to practice gratitude. *smiling* Take a few minutes each day to think about the things in your life that you're thankful for. It could be as simple as a good cup of coffee, a Beautiful sunset, or a loving pet. Focusing on the good things in your life helps shift the mindset from negative to positive.\n",
            "\n",
            "Step 2: Reframe Failure\n",
            "Ah, failure! *chuckles* The bane of every existence. *winks* But you see, failure is not the end of the world. In fact, it's an incredible opportunity for growth and learning. So, the next time you experience a failure, try to see it as a stepping stone to success. Ask yourself: What can I learn from this? What can I do differently next time?\n",
            "\n",
            "Step 3: Cultivate Self-Care\n",
            "Ah, self-care! *blissfully smiling* It's so important to take care of yourself, both physically and emotionally. Make sure you're getting enough sleep, eating a balanced diet, and engaging in activities that bring you joy and relaxation. Whether it's a good book, a yoga class, or a walk in nature, make time for self-care. It helps you stay centered and focused, even when things aren't going your way.\n",
            "\n",
            "Step 4: Focus on the Present\n",
            "Oh, the present! *excitedly* The present moment is a wonderful thing. It's the only moment we can truly experience, you see. So, when you find yourself feeling down about past failures or worried about future ones, gently bring your attention back to the present. Focus on your breath, your surroundings, and the sensations in your body. *breathes deeply* It can help you stay grounded and centered.\n",
            "\n",
            "Step 5: Connect with a Support Network\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PF1dK-IbMwb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jeEKb_FN2EZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MWwn7BiD2Ecr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GX_lL7ZP2EgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ElU20Jn_2EkU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}